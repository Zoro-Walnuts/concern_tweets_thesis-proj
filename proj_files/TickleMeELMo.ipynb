{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482c128d-7807-45a4-843b-7aab5ed458aa",
   "metadata": {},
   "source": [
    "# ELMo-LSA-SVM Model\n",
    "- Uses GPU if available\n",
    "- Creates pickle files for the ELMo embeddings under \"/embeddings/ELMo/\"\n",
    "\n",
    "---\n",
    "\n",
    "**TODO**\n",
    "- LSA Step\n",
    "- SVM Step\n",
    "- Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e4e57f-aa0e-4aab-a35b-3739d8952084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 01:38:04.212151: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732297084.247298    1609 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732297084.257258    1609 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/walnuts/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## turn off warnings for cleaner execution\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "## IMPORTS\n",
    "# ELMo\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preprocessing\n",
    "import csv\n",
    "import chardet\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import demoji\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c8ea2f-3b8f-461c-bd1c-bffd8fce5528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# check if gpu is being used\n",
    "num_gpu = len(tf.config.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available: \", num_gpu)\n",
    "\n",
    "print(\"Using GPU\" if num_gpu > 0 else \"Not Using GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af4d94e-114c-43e4-a3ab-d744fac4667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows: 2147\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date posted</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@fudaishii</td>\n",
       "      <td>i'm genuinely going to attempt tonight i can't do this anymore i can't handle all this stress i wish i was never born bro</td>\n",
       "      <td>9/11/24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@yourdystiny</td>\n",
       "      <td>Becoming less reactive is a huge part of growth &amp; decreasing stress. If you let everything get you worked up, you’ll damage your mind, body &amp; spirit.</td>\n",
       "      <td>9/8/24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ocenhxu</td>\n",
       "      <td>me ??? tired ??? stressed ??? exhausted ??? i wanna cry ??? yes.</td>\n",
       "      <td>9/8/24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ifeelgoodto</td>\n",
       "      <td>skipping meals, irregular sleeping habits, overthinking, stress, tired and drained. that's me, that's my everyday life</td>\n",
       "      <td>9/10/24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ysuckme</td>\n",
       "      <td>you deserve to be happy. not confused, not hurt, not stressed, just happy.</td>\n",
       "      <td>9/8/24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Username  \\\n",
       "0    @fudaishii   \n",
       "1  @yourdystiny   \n",
       "2      @ocenhxu   \n",
       "3  @ifeelgoodto   \n",
       "4      @ysuckme   \n",
       "\n",
       "                                                                                                                                                   Tweet  \\\n",
       "0                              i'm genuinely going to attempt tonight i can't do this anymore i can't handle all this stress i wish i was never born bro   \n",
       "1  Becoming less reactive is a huge part of growth & decreasing stress. If you let everything get you worked up, you’ll damage your mind, body & spirit.   \n",
       "2                                                                                       me ??? tired ??? stressed ??? exhausted ??? i wanna cry ??? yes.   \n",
       "3                                 skipping meals, irregular sleeping habits, overthinking, stress, tired and drained. that's me, that's my everyday life   \n",
       "4                                                                             you deserve to be happy. not confused, not hurt, not stressed, just happy.   \n",
       "\n",
       "  Date posted Label  \n",
       "0     9/11/24     1  \n",
       "1      9/8/24     0  \n",
       "2      9/8/24     1  \n",
       "3     9/10/24     0  \n",
       "4      9/8/24     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset / read csv\n",
    "# MAKE SURE CSV IS IN UTF-8 (if tweets have emojis)\n",
    "\n",
    "## Testing if csv can open (Use for troubleshooting)\n",
    "# with open('Eng_Tweets.csv') as csv_file:\n",
    "#   csvFile = csv.reader(csv_file, delimiter=',')\n",
    "#   for row in csv_file:\n",
    "#     print(row)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "csv_path = 'Eng_Tweets.csv'\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "print(\"total rows: \" + str(len(df)))\n",
    "df.head() ## head won't show emojis unless using print function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700226b-a641-4d3c-80b0-520757dba866",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- Remove mentions (@)\n",
    "- Remove hashtags (#)\n",
    "- Remove URLs\n",
    "- Replace emojis with textual description (Using demoji)\n",
    "- Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "025fba1e-6627-477c-bc30-a5567a5690a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPROCESSING STEPS\n",
    "def clean_text(text):\n",
    "  # Remove mentions\n",
    "  text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
    "  # Remove hashtags\n",
    "  text = re.sub(r'#\\w+', '', text)\n",
    "  # Remove URLs\n",
    "  text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "  # Replace emoji with textual descriptions\n",
    "  text = demoji.replace_with_desc(text)\n",
    "  text = re.sub(r'(:[a-zA-Z\\s]+:)', r' \\1 ', text) # Add spaces around the shortcode\n",
    "  text = re.sub(r'(:[a-zA-Z\\s]+:)', lambda match: match.group(0).replace(' ', '_'), text)\n",
    "  text = text.strip()\n",
    "  return text\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "  words = text.split()\n",
    "  filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "  return ' '.join(filtered_words)\n",
    "\n",
    "df['Tweet'] = df['Tweet'].apply(clean_text)\n",
    "df['Tweet'] = df['Tweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f39128-a507-4168-bbcf-6b83912e0604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdaad30c-ae47-4a7f-8c62-9408815a4e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.loc[24])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb502271-e752-473e-a8eb-11633fa93754",
   "metadata": {},
   "source": [
    "## Run ELMo in batches\n",
    "- Splits data into train-test-validate (70%-20%-10%)\n",
    "- Uses the default ELMo model\n",
    "- Max Sequence Length for embedding padding\n",
    "- Done in batches to avoid computational overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab98181-e28b-4aa1-9d2f-27963af625a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the dataset into train, validation, and test\n",
    "def split_data(df, train_size=0.7, val_size=0.1, test_size=0.2):\n",
    "    # 70% into training 30% into validation + testing \n",
    "    train_df, temp_df = train_test_split(df, train_size=train_size, random_state=42)\n",
    "    \n",
    "    # 30% splits 10% into validation and 20% into testing\n",
    "    val_df, test_df = train_test_split(temp_df, train_size=val_size / (val_size + test_size), random_state=42)\n",
    "    \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e16df72a-407e-4306-89fa-36567e2e599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing elmo with padding\n",
    "def process_in_batches(df, batch_size=50, max_seq_length=280, pickle_dir=\"embeddings/ELMo/\"):\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    # Ensure the directory exists for saving pickled files\n",
    "    os.makedirs(pickle_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate over the dataframe in chunks of batch_size\n",
    "    for start_idx in range(0, num_rows, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_rows)\n",
    "        batch = df[\"Tweet\"].iloc[start_idx:end_idx]\n",
    "\n",
    "        # Measure time for each batch\n",
    "        start = time.time()\n",
    "        embeddings_tensor = elmo(tf.constant(batch))[\"elmo\"]\n",
    "        end = time.time()\n",
    "        \n",
    "        length = end - start\n",
    "        print(f\"Processed rows {start_idx} to {end_idx - 1}\")\n",
    "        print(\"Time Taken for batch: \", length, \"seconds\")\n",
    "        print(\"Embedding Shape for batch: \", embeddings_tensor.shape, \"\\n\")\n",
    "        \n",
    "        # Pad all sequences in the batch to the fixed max length\n",
    "        padded_batch_embeddings = []\n",
    "        for i in range(embeddings_tensor.shape[0]):\n",
    "            seq_length = embeddings_tensor[i].shape[0]\n",
    "            padding_needed = max_seq_length - seq_length\n",
    "            # Pad the sequence with zeros (pad to match the max length)\n",
    "            padded_seq = tf.pad(embeddings_tensor[i], [[0, padding_needed], [0, 0]], mode='CONSTANT')\n",
    "            padded_batch_embeddings.append(padded_seq)\n",
    "        \n",
    "        # Stack the padded embeddings into a tensor\n",
    "        padded_batch_embeddings = tf.stack(padded_batch_embeddings)\n",
    "\n",
    "        # Save the embeddings for this batch to a pickle file\n",
    "        pickle_file = os.path.join(pickle_dir, f\"batch_{start_idx}_embeddings.pkl\")\n",
    "        with open(pickle_file, 'wb') as f:\n",
    "            pickle.dump(padded_batch_embeddings.numpy(), f)\n",
    "        \n",
    "        print(f\"Saved embeddings for batch {start_idx} to {pickle_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27940868-20a4-405e-87a2-336de468c6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading elmo model at: \"https://tfhub.dev/google/elmo/2\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732297091.162046    1609 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3539 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded elmo model\n",
      "Processing train dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732297093.107365    1676 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed rows 0 to 49\n",
      "Time Taken for batch:  3.0125675201416016 seconds\n",
      "Embedding Shape for batch:  (50, 37, 1024) \n",
      "\n",
      "Saved embeddings for batch 0 to embeddings/ELMo/train/batch_0_embeddings.pkl\n",
      "Processed rows 50 to 99\n",
      "Time Taken for batch:  1.1658337116241455 seconds\n",
      "Embedding Shape for batch:  (50, 49, 1024) \n",
      "\n",
      "Saved embeddings for batch 50 to embeddings/ELMo/train/batch_50_embeddings.pkl\n",
      "Processed rows 100 to 149\n",
      "Time Taken for batch:  0.7889902591705322 seconds\n",
      "Embedding Shape for batch:  (50, 30, 1024) \n",
      "\n",
      "Saved embeddings for batch 100 to embeddings/ELMo/train/batch_100_embeddings.pkl\n",
      "Processed rows 150 to 199\n",
      "Time Taken for batch:  0.7993190288543701 seconds\n",
      "Embedding Shape for batch:  (50, 31, 1024) \n",
      "\n",
      "Saved embeddings for batch 150 to embeddings/ELMo/train/batch_150_embeddings.pkl\n",
      "Processed rows 200 to 249\n",
      "Time Taken for batch:  0.862567663192749 seconds\n",
      "Embedding Shape for batch:  (50, 32, 1024) \n",
      "\n",
      "Saved embeddings for batch 200 to embeddings/ELMo/train/batch_200_embeddings.pkl\n",
      "Processed rows 250 to 299\n",
      "Time Taken for batch:  0.24457216262817383 seconds\n",
      "Embedding Shape for batch:  (50, 31, 1024) \n",
      "\n",
      "Saved embeddings for batch 250 to embeddings/ELMo/train/batch_250_embeddings.pkl\n",
      "Processed rows 300 to 349\n",
      "Time Taken for batch:  0.9062938690185547 seconds\n",
      "Embedding Shape for batch:  (50, 35, 1024) \n",
      "\n",
      "Saved embeddings for batch 300 to embeddings/ELMo/train/batch_300_embeddings.pkl\n",
      "Processed rows 350 to 399\n",
      "Time Taken for batch:  0.9000093936920166 seconds\n",
      "Embedding Shape for batch:  (50, 34, 1024) \n",
      "\n",
      "Saved embeddings for batch 350 to embeddings/ELMo/train/batch_350_embeddings.pkl\n",
      "Processed rows 400 to 449\n",
      "Time Taken for batch:  0.25444507598876953 seconds\n",
      "Embedding Shape for batch:  (50, 34, 1024) \n",
      "\n",
      "Saved embeddings for batch 400 to embeddings/ELMo/train/batch_400_embeddings.pkl\n",
      "Processed rows 450 to 499\n",
      "Time Taken for batch:  0.25356364250183105 seconds\n",
      "Embedding Shape for batch:  (50, 34, 1024) \n",
      "\n",
      "Saved embeddings for batch 450 to embeddings/ELMo/train/batch_450_embeddings.pkl\n",
      "Processed rows 500 to 549\n",
      "Time Taken for batch:  0.2427520751953125 seconds\n",
      "Embedding Shape for batch:  (50, 35, 1024) \n",
      "\n",
      "Saved embeddings for batch 500 to embeddings/ELMo/train/batch_500_embeddings.pkl\n",
      "Processed rows 550 to 599\n",
      "Time Taken for batch:  0.25002026557922363 seconds\n",
      "Embedding Shape for batch:  (50, 34, 1024) \n",
      "\n",
      "Saved embeddings for batch 550 to embeddings/ELMo/train/batch_550_embeddings.pkl\n",
      "Processed rows 600 to 649\n",
      "Time Taken for batch:  1.021515130996704 seconds\n",
      "Embedding Shape for batch:  (50, 43, 1024) \n",
      "\n",
      "Saved embeddings for batch 600 to embeddings/ELMo/train/batch_600_embeddings.pkl\n",
      "Processed rows 650 to 699\n",
      "Time Taken for batch:  1.9491331577301025 seconds\n",
      "Embedding Shape for batch:  (50, 108, 1024) \n",
      "\n",
      "Saved embeddings for batch 650 to embeddings/ELMo/train/batch_650_embeddings.pkl\n",
      "Processed rows 700 to 749\n",
      "Time Taken for batch:  0.22399258613586426 seconds\n",
      "Embedding Shape for batch:  (50, 32, 1024) \n",
      "\n",
      "Saved embeddings for batch 700 to embeddings/ELMo/train/batch_700_embeddings.pkl\n",
      "Processed rows 750 to 799\n",
      "Time Taken for batch:  1.0463621616363525 seconds\n",
      "Embedding Shape for batch:  (50, 45, 1024) \n",
      "\n",
      "Saved embeddings for batch 750 to embeddings/ELMo/train/batch_750_embeddings.pkl\n",
      "Processed rows 800 to 849\n",
      "Time Taken for batch:  0.7653951644897461 seconds\n",
      "Embedding Shape for batch:  (50, 29, 1024) \n",
      "\n",
      "Saved embeddings for batch 800 to embeddings/ELMo/train/batch_800_embeddings.pkl\n",
      "Processed rows 850 to 899\n",
      "Time Taken for batch:  1.0002930164337158 seconds\n",
      "Embedding Shape for batch:  (50, 40, 1024) \n",
      "\n",
      "Saved embeddings for batch 850 to embeddings/ELMo/train/batch_850_embeddings.pkl\n",
      "Processed rows 900 to 949\n",
      "Time Taken for batch:  0.21565628051757812 seconds\n",
      "Embedding Shape for batch:  (50, 32, 1024) \n",
      "\n",
      "Saved embeddings for batch 900 to embeddings/ELMo/train/batch_900_embeddings.pkl\n",
      "Processed rows 950 to 999\n",
      "Time Taken for batch:  0.21507954597473145 seconds\n",
      "Embedding Shape for batch:  (50, 31, 1024) \n",
      "\n",
      "Saved embeddings for batch 950 to embeddings/ELMo/train/batch_950_embeddings.pkl\n",
      "Processed rows 1000 to 1049\n",
      "Time Taken for batch:  1.0155408382415771 seconds\n",
      "Embedding Shape for batch:  (50, 39, 1024) \n",
      "\n",
      "Saved embeddings for batch 1000 to embeddings/ELMo/train/batch_1000_embeddings.pkl\n",
      "Processed rows 1050 to 1099\n",
      "Time Taken for batch:  0.22024035453796387 seconds\n",
      "Embedding Shape for batch:  (50, 31, 1024) \n",
      "\n",
      "Saved embeddings for batch 1050 to embeddings/ELMo/train/batch_1050_embeddings.pkl\n",
      "Processed rows 1100 to 1149\n",
      "Time Taken for batch:  1.1278438568115234 seconds\n",
      "Embedding Shape for batch:  (50, 47, 1024) \n",
      "\n",
      "Saved embeddings for batch 1100 to embeddings/ELMo/train/batch_1100_embeddings.pkl\n",
      "Processed rows 1150 to 1199\n",
      "Time Taken for batch:  0.2582895755767822 seconds\n",
      "Embedding Shape for batch:  (50, 37, 1024) \n",
      "\n",
      "Saved embeddings for batch 1150 to embeddings/ELMo/train/batch_1150_embeddings.pkl\n",
      "Processed rows 1200 to 1249\n",
      "Time Taken for batch:  0.25911784172058105 seconds\n",
      "Embedding Shape for batch:  (50, 31, 1024) \n",
      "\n",
      "Saved embeddings for batch 1200 to embeddings/ELMo/train/batch_1200_embeddings.pkl\n",
      "Processed rows 1250 to 1299\n",
      "Time Taken for batch:  0.2636234760284424 seconds\n",
      "Embedding Shape for batch:  (50, 37, 1024) \n",
      "\n",
      "Saved embeddings for batch 1250 to embeddings/ELMo/train/batch_1250_embeddings.pkl\n",
      "Processed rows 1300 to 1349\n",
      "Time Taken for batch:  1.2839303016662598 seconds\n",
      "Embedding Shape for batch:  (50, 56, 1024) \n",
      "\n",
      "Saved embeddings for batch 1300 to embeddings/ELMo/train/batch_1300_embeddings.pkl\n",
      "Processed rows 1350 to 1399\n",
      "Time Taken for batch:  0.23240423202514648 seconds\n",
      "Embedding Shape for batch:  (50, 30, 1024) \n",
      "\n",
      "Saved embeddings for batch 1350 to embeddings/ELMo/train/batch_1350_embeddings.pkl\n",
      "Processed rows 1400 to 1449\n",
      "Time Taken for batch:  0.35118985176086426 seconds\n",
      "Embedding Shape for batch:  (50, 49, 1024) \n",
      "\n",
      "Saved embeddings for batch 1400 to embeddings/ELMo/train/batch_1400_embeddings.pkl\n",
      "Processed rows 1450 to 1499\n",
      "Time Taken for batch:  0.7914478778839111 seconds\n",
      "Embedding Shape for batch:  (50, 28, 1024) \n",
      "\n",
      "Saved embeddings for batch 1450 to embeddings/ELMo/train/batch_1450_embeddings.pkl\n",
      "Processed rows 1500 to 1501\n",
      "Time Taken for batch:  0.315427303314209 seconds\n",
      "Embedding Shape for batch:  (2, 22, 1024) \n",
      "\n",
      "Saved embeddings for batch 1500 to embeddings/ELMo/train/batch_1500_embeddings.pkl\n",
      "Total Time for Training Set: 25.344858646392822 seconds\n",
      "Processing validation dataset...\n",
      "Processed rows 0 to 49\n",
      "Time Taken for batch:  0.9061076641082764 seconds\n",
      "Embedding Shape for batch:  (50, 36, 1024) \n",
      "\n",
      "Saved embeddings for batch 0 to embeddings/ELMo/val/batch_0_embeddings.pkl\n",
      "Processed rows 50 to 99\n",
      "Time Taken for batch:  0.24676990509033203 seconds\n",
      "Embedding Shape for batch:  (50, 31, 1024) \n",
      "\n",
      "Saved embeddings for batch 50 to embeddings/ELMo/val/batch_50_embeddings.pkl\n",
      "Processed rows 100 to 149\n",
      "Time Taken for batch:  0.23379158973693848 seconds\n",
      "Embedding Shape for batch:  (50, 30, 1024) \n",
      "\n",
      "Saved embeddings for batch 100 to embeddings/ELMo/val/batch_100_embeddings.pkl\n",
      "Processed rows 150 to 199\n",
      "Time Taken for batch:  0.30115795135498047 seconds\n",
      "Embedding Shape for batch:  (50, 45, 1024) \n",
      "\n",
      "Saved embeddings for batch 150 to embeddings/ELMo/val/batch_150_embeddings.pkl\n",
      "Processed rows 200 to 214\n",
      "Time Taken for batch:  0.5071139335632324 seconds\n",
      "Embedding Shape for batch:  (15, 29, 1024) \n",
      "\n",
      "Saved embeddings for batch 200 to embeddings/ELMo/val/batch_200_embeddings.pkl\n",
      "Total Time for Validation Set: 2.6120667457580566 seconds\n",
      "Processing test dataset...\n",
      "Processed rows 0 to 49\n",
      "Time Taken for batch:  0.2539966106414795 seconds\n",
      "Embedding Shape for batch:  (50, 35, 1024) \n",
      "\n",
      "Saved embeddings for batch 0 to embeddings/ELMo/test/batch_0_embeddings.pkl\n",
      "Processed rows 50 to 99\n",
      "Time Taken for batch:  0.23371315002441406 seconds\n",
      "Embedding Shape for batch:  (50, 31, 1024) \n",
      "\n",
      "Saved embeddings for batch 50 to embeddings/ELMo/test/batch_50_embeddings.pkl\n",
      "Processed rows 100 to 149\n",
      "Time Taken for batch:  0.2225503921508789 seconds\n",
      "Embedding Shape for batch:  (50, 30, 1024) \n",
      "\n",
      "Saved embeddings for batch 100 to embeddings/ELMo/test/batch_100_embeddings.pkl\n",
      "Processed rows 150 to 199\n",
      "Time Taken for batch:  0.9465327262878418 seconds\n",
      "Embedding Shape for batch:  (50, 33, 1024) \n",
      "\n",
      "Saved embeddings for batch 150 to embeddings/ELMo/test/batch_150_embeddings.pkl\n",
      "Processed rows 200 to 249\n",
      "Time Taken for batch:  0.24499821662902832 seconds\n",
      "Embedding Shape for batch:  (50, 34, 1024) \n",
      "\n",
      "Saved embeddings for batch 200 to embeddings/ELMo/test/batch_200_embeddings.pkl\n",
      "Processed rows 250 to 299\n",
      "Time Taken for batch:  1.37648344039917 seconds\n",
      "Embedding Shape for batch:  (50, 55, 1024) \n",
      "\n",
      "Saved embeddings for batch 250 to embeddings/ELMo/test/batch_250_embeddings.pkl\n",
      "Processed rows 300 to 349\n",
      "Time Taken for batch:  1.0216174125671387 seconds\n",
      "Embedding Shape for batch:  (50, 38, 1024) \n",
      "\n",
      "Saved embeddings for batch 300 to embeddings/ELMo/test/batch_300_embeddings.pkl\n",
      "Processed rows 350 to 399\n",
      "Time Taken for batch:  0.2377934455871582 seconds\n",
      "Embedding Shape for batch:  (50, 33, 1024) \n",
      "\n",
      "Saved embeddings for batch 350 to embeddings/ELMo/test/batch_350_embeddings.pkl\n",
      "Processed rows 400 to 429\n",
      "Time Taken for batch:  0.7073986530303955 seconds\n",
      "Embedding Shape for batch:  (30, 32, 1024) \n",
      "\n",
      "Saved embeddings for batch 400 to embeddings/ELMo/test/batch_400_embeddings.pkl\n",
      "Total Time for Test Set: 6.195241451263428 seconds\n",
      "Generated Embeddings for entire dataset\n",
      "Total Time Taken:  6.195241451263428 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load ELMo default model\n",
    "print(\"Downloading elmo model at: \\\"https://tfhub.dev/google/elmo/2\\\"\")\n",
    "elmo = hub.load(\"https://tfhub.dev/google/elmo/2\").signatures[\"default\"]\n",
    "print(\"Loaded elmo model\")\n",
    "\n",
    "# Sequence length for padding (should be >= max tweet length in dataset)\n",
    "MAX_SEQ_LEN = 280\n",
    "\n",
    "# Assuming 'df' is the dataframe with your dataset and the column containing text is \"Tweet\"\n",
    "train_df, val_df, test_df = split_data(df, train_size=0.7, val_size=0.1, test_size=0.2)\n",
    "\n",
    "# Process the train, validation, and test data\n",
    "print(\"Processing train dataset...\")\n",
    "start_total = time.time()\n",
    "process_in_batches(train_df, batch_size=50, max_seq_length=MAX_SEQ_LEN, pickle_dir=\"embeddings/ELMo/train/\")\n",
    "end_total = time.time()\n",
    "print(f\"Total Time for Training Set: {end_total - start_total} seconds\")\n",
    "\n",
    "print(\"Processing validation dataset...\")\n",
    "start_total = time.time()\n",
    "process_in_batches(val_df, batch_size=50, max_seq_length=MAX_SEQ_LEN, pickle_dir=\"embeddings/ELMo/val/\")\n",
    "end_total = time.time()\n",
    "print(f\"Total Time for Validation Set: {end_total - start_total} seconds\")\n",
    "\n",
    "print(\"Processing test dataset...\")\n",
    "start_total = time.time()\n",
    "process_in_batches(test_df, batch_size=50, max_seq_length=MAX_SEQ_LEN, pickle_dir=\"embeddings/ELMo/test/\")\n",
    "end_total = time.time()\n",
    "print(f\"Total Time for Test Set: {end_total - start_total} seconds\")\n",
    "\n",
    "total_time = end_total - start_total\n",
    "print(\"Generated Embeddings for entire dataset\")\n",
    "print(\"Total Time Taken: \", total_time, \"seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
